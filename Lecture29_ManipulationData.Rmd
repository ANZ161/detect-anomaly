---
title: "Lecture 29 - Exploration of data"
output:
  html_document: default
  html_notebook: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook

### Lecture 29 - Exploring relationships in data

#### Further ideas

At this time we will try to perform some more data manipulations in order to explore more relationships. One possibility is to see how one engineering parameter e.g. Impedance is related to another e.g. phase.

#### Review of available data

We can read data stored in the file **DF_Data_Process.data**. This is `R` object serialized and stored as a file. This dataset contains more than 9 mln rows. 

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# read data into R environment
# ============= READ DATA =================
# Read our big data first ... 9 mln rows...
DF_Data_Process_All <- readRDS("DF_Data_Process.data")
# Dimension of dataset
dim(DF_Data_Process_All)
```


```{r}
# Read our small data  ... 
DF_Data_Process_Recent <- readRDS("DF_Data_Process_Recent.data")
# Dimension of dataset
dim(DF_Data_Process_Recent)
```

#### Join and visualize the data

We can make some better overview of data starting from 'recent' dataset. We join this dataset to more human readable format...

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
# ============= JOIN DATA =================
# data frame containing equipment information
DF_Equipm <- read_csv("DF_EquipmData.csv")
# data frame containing Event Names
DF_EvCode <- read_csv("DF_EvCodeDataProject.csv")

# Data manipulation and saving to the DF_TEMP
DF_TEMP <- DF_Data_Process_All %>% 
  # join to decode equipment serial number
  inner_join(DF_Equipm, by = "IDEquipment") %>% 
  # join to decode Event Code meaning
  inner_join(DF_EvCode, by = "EventCode") %>% 
  # select only column needed
  select(StartDate, Name, AnalogVal, EventText)
```

#### relationship Tubing Process

We can extract one parameter for machine 1

```{r}
Tub_P1 <- DF_TEMP %>% 
  filter(EventText == "Tubing Process, phase angle") %>% 
  filter(Name == "Machine #1") %>% 
  select(StartDate, AnalogVal)

Tub_R1  <- DF_TEMP %>% 
  filter(EventText == "Tubing Process, resistance Ohm") %>% 
  filter(Name == "Machine #1")%>% 
  select(StartDate, AnalogVal)

Tub_P2 <- DF_TEMP %>% 
  filter(EventText == "Tubing Process, phase angle") %>% 
  filter(Name == "Machine #2") %>% 
  select(StartDate, AnalogVal)

Tub_R2  <- DF_TEMP %>% 
  filter(EventText == "Tubing Process, resistance Ohm") %>% 
  filter(Name == "Machine #2")%>% 
  select(StartDate, AnalogVal)

Tub_P3 <- DF_TEMP %>% 
  filter(EventText == "Tubing Process, phase angle") %>% 
  filter(Name == "Machine #3") %>% 
  select(StartDate, AnalogVal)

Tub_R3  <- DF_TEMP %>% 
  filter(EventText == "Tubing Process, resistance Ohm") %>% 
  filter(Name == "Machine #3")%>% 
  select(StartDate, AnalogVal)

Tub_P4 <- DF_TEMP %>% 
  filter(EventText == "Tubing Process, phase angle") %>% 
  filter(Name == "Machine #4") %>% 
  select(StartDate, AnalogVal)

Tub_R4  <- DF_TEMP %>% 
  filter(EventText == "Tubing Process, resistance Ohm") %>% 
  filter(Name == "Machine #4")%>% 
  select(StartDate, AnalogVal)
```

Our goal will be to write a function that can join these data to be on x and y axis with corresponding index of time summarized as average by minute

```{r}
library(xts)
library(tidyverse)
## Turn this into function
# function to create new features from original feature...
feature_eng_ts <- function(x, funcToApply = c("mean", "min", "max", "sd")){
  #function will return new dataframe with new features
  #x = dataframe with columns to perform feature engineering, it must contain data from one specific category
  #tscolname = column name containing time series data
  #avcolname - column name contining data to perform manipulations
  #funcToApply - vector containing functions to apply data transformations
  # convert to xts object
  DF_M1_xts <- as.xts(x[ ,-1], order.by = as.POSIXct(x$StartDate))
  # aggregate by hour and create new features
  # convert periodicity from seconds to hours and apply some functions to create new features
  for(i in 1: length(funcToApply)){
    # apply functions and merge them  
    res <- period.apply(DF_M1_xts, endpoints(DF_M1_xts, "mins"), funcToApply[i])
    names(res) <- paste("AnalogVal_", funcToApply[i], sep = "")
    # merge new features together
    if(i == 1){
      DF_M1_newfeatures <- res
      } else {
        DF_M1_newfeatures <- merge(DF_M1_newfeatures, res)
        }
  }
  # return to the dataframe
  DF_M1_NF <- coredata(DF_M1_newfeatures) %>% as.data.frame(row.names = F)
  DF_M1_NF$StartDate <- index(DF_M1_newfeatures)
  # removing rows with missing data!!!
  DF_M1_NF <- na.omit(DF_M1_NF)
  # return result
  return(DF_M1_NF)
}

df_R1 <- feature_eng_ts(Tub_R1, "mean")
df_P1 <- feature_eng_ts(Tub_P1, "mean")
df_R2 <- feature_eng_ts(Tub_R2, "mean")
df_P2 <- feature_eng_ts(Tub_P2, "mean")
df_R3 <- feature_eng_ts(Tub_R3, "mean")
df_P3 <- feature_eng_ts(Tub_P3, "mean")
df_R4 <- feature_eng_ts(Tub_R4, "mean")
df_P4 <- feature_eng_ts(Tub_P4, "mean")

df_J1 <- inner_join(df_R1, df_P1, by = "StartDate") 
df_J1$Machine <- "Machine 1"
df_J2 <- inner_join(df_R2, df_P2, by = "StartDate")
df_J2$Machine <- "Machine 2"
df_J3 <- inner_join(df_R3, df_P3, by = "StartDate") 
df_J3$Machine <- "Machine 3"
df_J4 <- inner_join(df_R4, df_P4, by = "StartDate")
df_J4$Machine <- "Machine 4"


df_All <- bind_rows(df_J1, df_J2, df_J3, df_J4)

ggplot(df_All, aes(x = AnalogVal_mean.y, y = AnalogVal_mean.x, col = Machine)) + geom_point()

```



We can visualize this dataset, putting all the points together...



Almost impossible to gather any insights. It's just too much data in the graph...

#### Join and visualize the data - Your turn

1. Create separate visualizations for all 9 processes (use sample code below to start with).

```{r}
# Visualize the data...
DF_TEMP %>% 
  filter(EventText == "Cutting Process, phase angle") %>% 
  ggplot(aes(x = StartDate, y = AnalogVal, col = EventText)) + geom_point()+facet_grid(~Name)
```

Hint: you can copy/paste proposed code, write a `for` loop, etc

For your convenience, it's worth to use `for` loop using example as below

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# We can for loop those as well
library(magrittr)
# save our Event names into the vector 'Events'
Events <- DF_TEMP %>% select(EventText) %>% unique() %$% EventText
# make a for loop...
for(i in 1:length(Events)){
plots <- '...' %>% 
  filter(EventText == Events[i]) %>% 
  ggplot('...') + geom_point()+facet_grid(~Name) 
# and we will print plots
print(plots)
}
```


2. Can you already observe some differences between the same parameter in different machines? Which ones?

Hint: Pay attention on parameters level, how are those parameters distributed, etc

#### Same for larger dataset

1. Import and join bigger dataset

Hint: Use file `DF_Data_Process.data` to import bigger dataset

2. Create a generalized plot for that dataset

Hint: Use the for loop construct once again... data is quite big so running this code may take a while... also feel free to use `geom_smooth()` instead of `geom_point()`

3. Can you observe some tendencies in the parameters in different machines? Which ones?

Hint: Don't bother too much looking into that data. Answer can be even negative! Sometime human can not sence any tendency - it's normal!!!