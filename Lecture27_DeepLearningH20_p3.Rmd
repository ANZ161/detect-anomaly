---
title: "Lecture 27 - Into Deep Learning P3"
output:
  html_document: default
  html_notebook: default
  pdf_document: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook


### Lecture 27 - Your project. Deep Learning with H2O. P.2 Implement Deep Learning Model to ShinyApp

Deep Learning... This lecture is dedicated to the implementation of Deep Learning models into for our Data

#### Work overview (from previous lectures)

* re-arranging data as matrix - DONE
* fitting deep learning models - DONE
* testing the models - DONE
* saving models - DONE
* implementation in our ShinyApp... - to be covered in this lecture

In order to achieve this goal we will have to perform some steps:

1. Learn how to use saved model in R to make predictions
2. Develop and implement app usage strategy
3. Return to our time series to identify time of anomaly

#### Using saved h2o model in R

In the prevous lecture we have saved our Deep Learning Model in the www folder:

```{r, message=FALSE, warning=FALSE}
#files with model
file.info("www/tmp/normality_model.bin/DeepLearning_model_R_1510597411656_1")
```
One of the Goals of this lecture will be to see how to use this model in R to make predictions

From: (R h2o load a saved model from disk in MOJO or POJO format)[https://stackoverflow.com/questions/45335697/r-h2o-load-a-saved-model-from-disk-in-mojo-or-pojo-format]

We know that two types of strategy are possible

1. use a binary model 
2. export a model to MOJO (or POJO) form

#### Using Binary Model to make predictions

We will first use the first option to actually keep H2O on the background to make predictions

```{r, message=FALSE, warning=FALSE}
library(h2o)
library(tidyverse)
library(plotly)
```

Initializing H2O and loading the model

```{r, eval=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# initialize h2o
h2o.init()
# load model
normality_model <- h2o.loadModel("www/tmp/normality_model.bin/DeepLearning_model_R_1510597411656_1") 
```

We will also need to quickly construct the dataset we can predict the result

```{r, message=FALSE, warning=FALSE}

# ============= READ DATA =================
# Read our small data ... 
DF_Data_Recent <- readRDS("DF_Data_Process_Recent.data") 

DF_Equipm <- read_csv("DF_EquipmData.csv")
# data frame containing Event Names
DF_EvCode <- read_csv("DF_EvCodeDataProject.csv")

# Data manipulation and saving to the DF_TEMP
DF_TEMP <- DF_Data_Recent %>% 
  # join to decode equipment serial number
  inner_join(DF_Equipm, by = "IDEquipment") %>% 
  # join to decode Event Code meaning
  inner_join(DF_EvCode, by = "EventCode") %>% 
  # select only column needed
  select(StartDate, Name, AnalogVal, EventText)
```


Will be using Machine #4 for that

```{r}
# importing R function from file
source("to_matrix.R")

DF_M4 <- DF_TEMP %>% 
  to_matrix(filter_Event = "Tubing Process, resistance Ohm",
            filter_Machine = "Machine #4",n_cols = 150)
```


#### Predicting anomaly on Machine 4

In order to predict on `DF_M4` dataset we need to make it H2OFrame class. We need to load this object into H2O environment

```{r}
# load dataset into H2O environment
test_M4  <- as.h2o(x = DF_M4, destination_frame = "test_M4")
```


```{r}
# plot the anomalies
h2o.anomaly(normality_model, test_M4) %>% as.data.frame() %>% plot.ts(type = "p")
```

This brings us to the point of create a 'cutoff' which I will set as 0.25. MSE values scored above this value will be identifyed as anomaly. 

```{r}
# save MSE values
mse_out <- h2o.anomaly(normality_model, test_M4) %>% as.data.frame()
# filter anomalies
rows_anomals <- which(mse_out > 0.25)
rows_normals <- which(mse_out <= 0.25)
```

Using these rows we can 'label' or subset our anomalous observations

```{r}
# subset rows with matrices that shows the anomalies
matr_anomals <- DF_M4[rows_anomals, ]

# subset rows with matrices that does not show the anomalies
matr_normals <- DF_M4[rows_normals, ] 
```

Just out of curiosity I will plot the anomalies values as 3D plot

```{r, eval=FALSE, include=TRUE}
plot_ly(z = matr_anomals, type = "surface")
```
![Extracted observations with anomaly][id1]

This is wonderful! High anomalous spikes were detected!

And also those without

```{r, eval=FALSE, include=TRUE}
plot_ly(z = matr_normals, type = "surface")
```

There is no spikes! 

![Data points without anomaly][id2]

#### Catching corresponding dates & time

Once we learned to process our data through the model, split 'faulty' observations we will need to come back to reference our faulty observations over time. Perhaps there are ways to solve this problem in a more efficient way, but I will attempt to:

* extract corresponding date time
* extract matrixes with faults for both values and time
* convert matrices to vectors
* join faulty observations with corresponding time, add new column with label "1"
* join 'good' observations with corresponding time, add new column with label "0"
* construct the dataframes and arrange them back

To extract the time... I have modified our function that extracts `AnalogVal` variable and saved that to the R script `to_matrixDT.R`

```{r}
# importing R function from file
source("to_matrixDT.R")
```

Let's use this function to extract corresponding Date and Time...

```{r, eval=TRUE, include=TRUE}
# prepared matrix containing date and time elements
DF_M4DT <- to_matrixDT(DF_TEMP, 
                   filter_Event = "Tubing Process, resistance Ohm",
                   filter_Machine = "Machine #4", 
                   n_cols = 150)
```

now I can extract corresponding matrixes

```{r}
# subset rows with matrices that shows the anomalies
matr_anomals <- DF_M4[rows_anomals, ]
matr_anomalT <- DF_M4DT[rows_anomals, ] #corresponding time date index

# subset rows with matrices that does not show the anomalies
matr_normals <- DF_M4[rows_normals, ] 
matr_normalT <- DF_M4DT[rows_normals, ] #corresponding time date index
```

Convert to vectors, join and mutate

```{r}
# For anomalies
DF_4V <- matr_anomals %>% t() %>% c() %>% as.data.frame() 
colnames(DF_4V) <- "AnalogVal"
DF_4T <- matr_anomalT %>% t() %>% c() %>% as.POSIXct() %>%  as.data.frame() 
colnames(DF_4T) <- "StartDate"
DF_A <- DF_4T %>% bind_cols(DF_4V) %>% mutate(Anomaly = "Yes")

# For normalities
DF_4V <- matr_normals %>% t() %>% c() %>% as.data.frame() 
colnames(DF_4V) <- "AnalogVal"
DF_4T <- matr_normalT %>% t() %>% c() %>% as.POSIXct() %>% as.data.frame()
colnames(DF_4T) <- "StartDate"
DF_N <- DF_4T %>% bind_cols(DF_4V) %>% mutate(Anomaly = "No")

# join DF_A and DF_N...
DF_M4L <- DF_A %>% bind_rows(DF_N) %>% arrange(StartDate)


```

Let's plot this

```{r}
ggplot(DF_M4L, aes(x = StartDate, y = AnalogVal, col = as.factor(Anomaly))) + geom_line()
```

Indeed it make sense! This is what we want for our shinyapp...

Still some steps to do: 

#### try to merge the MSE and interpret as anomaly level

Of course these manipulations with vectors and matrixes are possible. We can pack them to functions and so on. Before implementation, what about to simply convert the obtained result to another column that we can plot in parallel as a level of probability to have an anomaly in the data...

This will be less cumbersome and will give operators of the process possibility to have more clear understanding for interpretation...

```{r}
# mse_out is a dataframe containing MSE error for each row of the matrix, we replicate this... 150 times...
DF_M4mse <- do.call(cbind, replicate(150, as.matrix(mse_out), simplify=FALSE))

# going to combine this result with our objects DF_M4 and DF_M4DT
DF_V <- DF_M4 %>% t() %>% c() %>% as.data.frame() 
colnames(DF_V) <- "AnalogVal"
DF_T <- DF_M4DT %>% t() %>% c() %>% as.POSIXct() %>%  as.data.frame() 
colnames(DF_T) <- "StartDate"
DF_A <- DF_M4mse %>% t() %>% c() %>% as.data.frame() 
colnames(DF_A) <- "AnomalyRating"

DF_F <- DF_V %>% bind_cols(DF_T, DF_A)

library(RColorBrewer)
mypalette<-brewer.pal(3,"Paired")

myspecial <- c("#91cf60", "#ffffbf", "#fc8d59")

ggplot(DF_F, aes(x = StartDate, y = AnalogVal, colour = AnomalyRating)) + geom_line() + scale_colour_gradientn(colours=myspecial)

```


```{r}
ggplot(DF_F, aes(x = StartDate, y = AnalogVal, colour = AnomalyRating)) + geom_line() + 
  geom_linerange(data=DF_F,aes(ymin=AnalogVal, ymax=AnalogVal + AnomalyRating*50))
  


```

#### Time to Shiny?

sasdfasfasfasfasdfasdfasf
asdfasfasdfasdfasdfasdfasdf
asdfasdfasdfasdfasfasdfasdf


And let's not forget to switch off our cluster!
```{r, eval=TRUE, include=TRUE}
h2o.shutdown(prompt= FALSE)

```

#### Conclusion




#### Next step

...


#### used references

example from: (https://dzone.com/articles/anomaly-detection-with-deep-learning-in-r-with-h2o)[https://dzone.com/articles/anomaly-detection-with-deep-learning-in-r-with-h2o]

More reading: (https://dzone.com/articles/the-basics-of-deep-learning-how-to-apply-it-to-pre?fromrel=true)[https://dzone.com/articles/the-basics-of-deep-learning-how-to-apply-it-to-pre?fromrel=true]

The phylosophy that was already explained in the course (I discovered that later...:) : (https://dzone.com/articles/dive-deep-into-deep-learning-using-h2o-1)[https://dzone.com/articles/dive-deep-into-deep-learning-using-h2o-1]

And: (https://shiring.github.io/machine_learning/2017/05/01/fraud)[https://shiring.github.io/machine_learning/2017/05/01/fraud]

paper: (https://arxiv.org/abs/1701.01887)[https://arxiv.org/abs/1701.01887]
In this lecture we would explore the 'technology' on the sample and try to do this in 10 min lecture!



[id1]: plots/M4_anomaly.png "Extracted observations with anomaly"
[id2]: plots/M4_no_anomaly.png "Observations without anomaly"



