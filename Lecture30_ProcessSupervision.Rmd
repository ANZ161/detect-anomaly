---
title: "Creating Anomaly Detection System for Industrial Process with Deep Learning"
output:
  html_document: default
  html_notebook: default
  pdf_document: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook


### Your project - Detect Anomaly in Industrial Process with Deep Learning

Deep Learning... In this lecture I would like to esplore with you the DeepLearning we can do with H2O package in R...

### Data Exploration

```{r}
# libraries
library(tidyverse)
library(plotly)

# data reading
DF_NORMAL <- read_rds("DATA-normal.rds")
DF_TEST <- read_rds("DATA-test.rds")
DF_ANOMALY <- read_rds("DATA-anomaly.rds")

# names of the dataset columns
names(DF_NORMAL)
```

### About the NORMAL dataset

```{r}
NORM_2016 <- DF_NORMAL %>% select(2:11) %>% as.matrix() 
summary(NORM_2016)

```

This dataset was selected .. after .. the period of deep process maintenance

```{r}
plot_ly(z = NORM_2016, type = "surface")
```

### About the TEST dataset

This dataset contains some values that may indicate potential anomaly

```{r}
TEST_2015 <- DF_TEST %>% select(2:11) %>% as.matrix()
plot_ly(z = TEST_2015, type = "surface")

```

### About the ANOMALY dataset

This dataset contains some values that indicate the anomaly

```{r}

TEST_2017 <- DF_ANOMALY %>% select(2:11) %>% as.matrix()
plot_ly(z = TEST_2017, type = "surface")

```

Summary: 3 dataset were selected!








#### Train Deep Learning Model





```{r}
library(h2o)
h2o.init(nthreads = 2)

train <- as.h2o(x = NORM_2016, destination_frame = "train")
test <- as.h2o(x = TEST_2015, destination_frame = "test")
anomaly <- as.h2o(x = TEST_2017, destination_frame = "anomaly")

# ?h2o.deeplearning

normality_model <- h2o.deeplearning(x = names(train), 
                                     training_frame = train, 
                                     activation = "Tanh", 
                                     autoencoder = TRUE, 
                                     hidden = c(8,5,8), 
                                     sparse = TRUE,
                                     l1 = 1e-4, 
                                     epochs = 100)


```

#### reconstruct dataset

```{r}
# recreate 
test_recon <- h2o.predict(normality_model, train) %>% as.matrix()
plot_ly(z = test_recon, type = "surface")
```

#### Check MSE


```{r}

mse <- h2o.anomaly(normality_model, train) %>% as.data.frame()
mse_test <- h2o.anomaly(normality_model, test) %>% as.data.frame()
mse_anom <- h2o.anomaly(normality_model, anomaly) %>% as.data.frame()

mse$label <- "normal"
mse_test$label <- "test"
msejoined <- rbind(mse, mse_test)
msejoined$index <- 1:nrow(msejoined)

ggplot(msejoined, aes(x = index, y = Reconstruction.MSE, col = as.factor(label))) + geom_line()

plot.ts(mse)
plot.ts(mse_test)
plot.ts(mse_anom)


mse_anom$label <- "anomaly"
mse_all <- rbind(mse,mse_test, mse_anom)
mse_all$index <- 1:nrow(mse_all)
ggplot(mse_all, aes(x = index, y = Reconstruction.MSE, col = as.factor(label))) + geom_line()

```

# shutdown JVM
```{r}
h2o.shutdown(prompt = F)
```


Homework:

- try different activation function, each time calculate MSE
- try sparse false parameter, what is changing?
- try high and veryhigh complexity of the model, calculate MSE, conclude which one is the best
- try 10:100:10 is it work?
- try 200:200 will it work? what is the resulting MSE
- try 5 hidden layers
- try replicate_training data = False, how much time is different?
- weights_column this is the observation weight, try to add 1 column with observation weights of importance! see help
