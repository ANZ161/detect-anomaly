---
title: "Lecture 23 - Time-Series. Feature Engineering"
output:
  html_document: default
  html_notebook: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook

### Lecture 24 - Your project. Specialized R packages, AnomalyDetection

Hello everybody. Welcome back to one another bonus lecture. This one will be dedicated to specialized packages in R that are helping us to detect anomalies. We will see how to use package 'AnomalyDetection' on the example on our data.

As usual, we will get a brief review of the functionalities and see how can we apply that in our ShinyApp

#### Package AnomalyDetection

This package can be found on github.com: https://github.com/twitter/AnomalyDetection

Main idea is that we provide our data to the function which will attempt to get the anomalies taking assumption that **Anomaly** is "Something different" from usual! Function is using Seasonal Hybrid ESD method. It is **computationally intensive** method. Intuitevely, it is using statistical methods. Decomposition of time-series, finding `the robust statistical median`, `Median Absolute Deviation`... not a **Deep Learning**... 

Apparently, as described in this paper [https://arxiv.org/pdf/1704.07706.pdf](https://arxiv.org/pdf/1704.07706.pdf), **twitter** is using this to detect traffic anomalies and provision additional computing capacity. This way, everybody can send their tweet!!! 

##### Extracting data

In order to move things forward we will use the data from one process and one machine. Following chunk of code will get the data for us:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
# devtools::install_github("twitter/AnomalyDetection")
library(AnomalyDetection)

# ============= READ DATA =================
# Read our big data first ... 9 mln rows...
DF_Data_All <- readRDS("DF_Data_Process.data")
# data about equipment
DF_Equipm <- read_csv("DF_EquipmData.csv")
# data frame containing Event Names
DF_EvCode <- read_csv("DF_EvCodeDataProject.csv")

# Data manipulation and saving to the DF_TEMP
DF_TEMP <- DF_Data_All %>% 
  # join to decode equipment serial number
  inner_join(DF_Equipm, by = "IDEquipment") %>% 
  # join to decode Event Code meaning
  inner_join(DF_EvCode, by = "EventCode") %>% 
  # select only column needed
  select(StartDate, Name, AnalogVal, EventText)

# ============= END OF READ DATA =================

```

Further on we will extract two process for two different machines

```{r}
# extract data for one machine and one sub-process
DF_M3_Cut_Ph <- DF_TEMP %>% 
  filter(EventText == "Cutting Process, phase angle") %>% 
  filter(Name == "Machine #3") %>% 
  select(StartDate, AnalogVal)

dim(DF_M3_Cut_Ph) # 82883 rows
```

```{r}
# extract data for one machine and one sub-process
DF_M3_Tub_Res <- DF_TEMP %>% 
  filter(EventText == "Tubing Process, resistance Ohm") %>% 
  filter(Name == "Machine #3") %>% 
  select(StartDate, AnalogVal) %>% 
  arrange(StartDate)

dim(DF_M3_Tub_Res) # 332620 rows

```


##### Apply function of anomaly detection

Once we have our data frames with one parameter we can directly provide that to the function

```{r}
# applied to our data
res = AnomalyDetectionTs(DF_M3_Cut_Ph, max_anoms=0.02, direction='both', plot=TRUE)
# getting out plot
res$plot
```

Things to notice function is quite long to run for a normal CPU. Nevertheless it works. A bit weird to state that there are 2% of anomalies before running the function, inst't it...

And for another machine where we have 332000 rows this function was simply not giving result after 10 minutes, For that our data frame will be limited to only 50000 rows...

```{r}
# applied to our data
res2 <- DF_M3_Tub_Res %>% 
  tail(50000) %>% 
  AnomalyDetectionTs(max_anoms=0.02, direction='both', plot=TRUE)
# getting out plot
res2$plot
```

Intresting to see  that function runs very nice to detect anomalies! 

Naiive question: How will it work if there are no anomalies???

```{r}
# extract data for one machine and one sub-process
DF_M1_Tub_Res <- DF_TEMP %>% 
  filter(EventText == "Tubing Process, resistance Ohm") %>% 
  filter(Name == "Machine #1") %>% 
  select(StartDate, AnalogVal) %>% 
  arrange(StartDate)

dim(DF_M1_Tub_Res) # 344084 rows

```

```{r}
# applied to our data
res3 <- DF_M1_Tub_Res %>% 
  tail(50000) %>% 
  AnomalyDetectionTs(max_anoms=0.02, direction='both', plot=TRUE)
# getting out plot
res3$plot
```






How was that on the beginning of the period?

```{r}
# get less rows to run function
DF_M3_Tub_Res_Rec <- DF_M3_Tub_Res %>% head(50000)
```

```{r}
# applied to our data
res3 = AnomalyDetectionTs(DF_M3_Tub_Res_Rec, max_anoms=0.02, direction='both', plot=TRUE)
# getting out plot
res3$plot
```

It seems that we are discovering really something interesting!!!

Before we go into implementing that in our ShinyApp let's play with parameters a bit

##### direction 'pos' or 'neg'

This parameter will allow us to detect only anomalies that are more 'positive' from the mean. This might be quite relevant for example in cases when you know the nature of the data you are looking into...

```{r}
# applied to our data
res4 = AnomalyDetectionTs(DF_M3_Tub_Res_Rec, max_anoms=0.02, direction='pos', plot=TRUE)
# getting out plot
res4$plot
```

##### only_last

If you are looking to only report anomalies in the last day or hour this parameter can be set up

```{r}
# applied to our data
res5 = AnomalyDetectionTs(DF_M3_Tub_Res_Rec, max_anoms=0.02, direction='pos', only_last = 'day', plot=TRUE)
# getting out plot
res5$plot
```

##### piecewise_median_period_weeks

Function learns to detect anomaly taking into account some period of data. By default it is 2 weeks. For that function will not work if we will supply data that is less than that

```{r}
# get less rows to run function
DF_M3_Tub_Res_5000 <- DF_M3_Tub_Res %>% head(5000)
```

Error will be given

```{r}
# applied to our data
res5.1 = AnomalyDetectionTs(DF_M3_Tub_Res_5000, max_anoms=0.02, direction='pos', 
                          y_log = TRUE, plot=TRUE)
# getting out plot
res5.1$plot
```

##### longterm_period

For long time series we can increase detection eficacy

```{r}
# applied to our data
res5.3 = AnomalyDetectionTs(DF_M3_Tub_Res_Rec, max_anoms=0.02, direction='pos',longterm = T, 
                            plot=TRUE)
# getting out plot
res5.3$plot
```


##### y_log

We can benefit from log scaling, in our case we don't really have large positive anomalies...

```{r}
# applied to our data
res6 = AnomalyDetectionTs(DF_M3_Tub_Res_Rec, max_anoms=0.02, direction='pos', 
                          y_log = TRUE, plot=TRUE)
# getting out plot
res6$plot
```

#### Implementation in Shiny...

In order to implement that in Shiny we will need to take into account several facts:

* longer time to run function
* must use larger dataset in order to allow function to run properly

For that the idea will be to use the larger dataset and to limit number of rows for each machine/ process to be maximum 50000

We will only keep new functionality for the App
